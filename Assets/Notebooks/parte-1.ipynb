{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# MARATONA BEHIND THE CODE 2020\n",
    "\n",
    "## DESAFIO 2: PARTE 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em projetos de ciência de dados visando a construção de modelos de *machine learning*, ou aprendizado estatístico, é muito incomum que os dados iniciais estejam já no formato ideal para a construção de modelos. São necessários vários passos intermediários de pré-processamento de dados, como por exemplo a codificação de variáveis categóricas, normalização de variáveis numéricas, tratamento de dados faltantes, etc. A biblioteca **scikit-learn** -- uma das mais populares bibliotecas de código-aberto para *machine learning* no mundo -- possui diversas funções já integradas para a realização das transformações de dados mais utilizadas. Entretanto, em um fluxo comum de um modelo de aprendizado de máquina, é necessária a aplicação dessas transformações pelo menos duas vezes: a primeira vez para \"treinar\" o modelo, e depois novamente quando novos dados forem enviados como entrada para serem classificados por este modelo. \n",
    "\n",
    "Para facilitar o trabalho com esse tipo de fluxo, o scikit-learn possui também uma ferramenta chamada **Pipeline**, que nada mais é do que uma lista ordenada de transformações que devem ser aplicadas nos dados. Para auxiliar no desenvolvimento e no gerenciamento de todo o ciclo-de-vida dessas aplicações, alem do uso de Pipelines, as equipes de cientistas de dados podem utilizar em conjunto o **Watson Machine Learning**, que possui dezenas de ferramentas para treinar, gerenciar, hospedar e avaliar modelos baseados em aprendizado de máquina. Além disso, o Watson Machine Learning é capaz de encapsular pipelines e modelos em uma API pronta para uso e integração com outras aplicações.\n",
    "\n",
    "Durante o desafio 2, você participante irá aprender a construir uma **Pipeline** para um modelo de classificação e hospedá-lo como uma API com o auxílio do Watson Machine Learning. Uma vez hospedado, você poderá integrar o modelo criado com outras aplicações, como assistentes virtuais e muito mais. Neste notebook, será apresentado um exemplo funcional de criação de um modelo e de uma pipeline no scikit-learn (que você poderá utilizar como template para a sua solução!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ** ATENÇÃO **\n",
    "\n",
    "Este notebook serve apenas um propósito educativo, você pode alterar o código como quiser e nada aqui será avaliado/pontuado.\n",
    "\n",
    "A recomendação é que você experimente e teste diferentes algoritmos aqui antes de passar para a *parte-2*, onde será realizado o deploy do seu modelo no **Watson Machine Learning** :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabalhando com Pipelines do scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "pying sklearn\\feature_extraction\\__init__.py -> build\\lib.win32-3.8\\sklearn\\feature_extraction\n    creating build\\lib.win32-3.8\\sklearn\\feature_extraction\\tests\n    copying sklearn\\feature_extraction\\tests\\test_dict_vectorizer.py -> build\\lib.win32-3.8\\sklearn\\feature_extraction\\tests\n    copying sklearn\\feature_extraction\\tests\\test_feature_hasher.py -> build\\lib.win32-3.8\\sklearn\\feature_extraction\\tests\n    copying sklearn\\feature_extraction\\tests\\test_image.py -> build\\lib.win32-3.8\\sklearn\\feature_extraction\\tests\n    copying sklearn\\feature_extraction\\tests\\test_text.py -> build\\lib.win32-3.8\\sklearn\\feature_extraction\\tests\n    copying sklearn\\feature_extraction\\tests\\__init__.py -> build\\lib.win32-3.8\\sklearn\\feature_extraction\\tests\n    creating build\\lib.win32-3.8\\sklearn\\manifold\n    copying sklearn\\manifold\\isomap.py -> build\\lib.win32-3.8\\sklearn\\manifold\n    copying sklearn\\manifold\\locally_linear.py -> build\\lib.win32-3.8\\sklearn\\manifold\n    copying sklearn\\manifold\\mds.py -> build\\lib.win32-3.8\\sklearn\\manifold\n    copying sklearn\\manifold\\setup.py -> build\\lib.win32-3.8\\sklearn\\manifold\n    copying sklearn\\manifold\\spectral_embedding_.py -> build\\lib.win32-3.8\\sklearn\\manifold\n    copying sklearn\\manifold\\t_sne.py -> build\\lib.win32-3.8\\sklearn\\manifold\n    copying sklearn\\manifold\\__init__.py -> build\\lib.win32-3.8\\sklearn\\manifold\n    creating build\\lib.win32-3.8\\sklearn\\manifold\\tests\n    copying sklearn\\manifold\\tests\\test_isomap.py -> build\\lib.win32-3.8\\sklearn\\manifold\\tests\n    copying sklearn\\manifold\\tests\\test_locally_linear.py -> build\\lib.win32-3.8\\sklearn\\manifold\\tests\n    copying sklearn\\manifold\\tests\\test_mds.py -> build\\lib.win32-3.8\\sklearn\\manifold\\tests\n    copying sklearn\\manifold\\tests\\test_spectral_embedding.py -> build\\lib.win32-3.8\\sklearn\\manifold\\tests\n    copying sklearn\\manifold\\tests\\test_t_sne.py -> build\\lib.win32-3.8\\sklearn\\manifold\\tests\n    copying sklearn\\manifold\\tests\\__init__.py -> build\\lib.win32-3.8\\sklearn\\manifold\\tests\n    creating build\\lib.win32-3.8\\sklearn\\metrics\n    copying sklearn\\metrics\\base.py -> build\\lib.win32-3.8\\sklearn\\metrics\n    copying sklearn\\metrics\\classification.py -> build\\lib.win32-3.8\\sklearn\\metrics\n    copying sklearn\\metrics\\pairwise.py -> build\\lib.win32-3.8\\sklearn\\metrics\n    copying sklearn\\metrics\\ranking.py -> build\\lib.win32-3.8\\sklearn\\metrics\n    copying sklearn\\metrics\\regression.py -> build\\lib.win32-3.8\\sklearn\\metrics\n    copying sklearn\\metrics\\scorer.py -> build\\lib.win32-3.8\\sklearn\\metrics\n    copying sklearn\\metrics\\setup.py -> build\\lib.win32-3.8\\sklearn\\metrics\n    copying sklearn\\metrics\\__init__.py -> build\\lib.win32-3.8\\sklearn\\metrics\n    creating build\\lib.win32-3.8\\sklearn\\metrics\\cluster\n    copying sklearn\\metrics\\cluster\\bicluster.py -> build\\lib.win32-3.8\\sklearn\\metrics\\cluster\n    copying sklearn\\metrics\\cluster\\setup.py -> build\\lib.win32-3.8\\sklearn\\metrics\\cluster\n    copying sklearn\\metrics\\cluster\\supervised.py -> build\\lib.win32-3.8\\sklearn\\metrics\\cluster\n    copying sklearn\\metrics\\cluster\\unsupervised.py -> build\\lib.win32-3.8\\sklearn\\metrics\\cluster\n    copying sklearn\\metrics\\cluster\\__init__.py -> build\\lib.win32-3.8\\sklearn\\metrics\\cluster\n    creating build\\lib.win32-3.8\\sklearn\\metrics\\cluster\\tests\n    copying sklearn\\metrics\\cluster\\tests\\test_bicluster.py -> build\\lib.win32-3.8\\sklearn\\metrics\\cluster\\tests\n    copying sklearn\\metrics\\cluster\\tests\\test_common.py -> build\\lib.win32-3.8\\sklearn\\metrics\\cluster\\tests\n    copying sklearn\\metrics\\cluster\\tests\\test_supervised.py -> build\\lib.win32-3.8\\sklearn\\metrics\\cluster\\tests\n    copying sklearn\\metrics\\cluster\\tests\\test_unsupervised.py -> build\\lib.win32-3.8\\sklearn\\metrics\\cluster\\tests\n    copying sklearn\\metrics\\cluster\\tests\\__init__.py -> build\\lib.win32-3.8\\sklearn\\metrics\\cluster\\tests\n    creating build\\lib.win32-3.8\\sklearn\\metrics\\tests\n    copying sklearn\\metrics\\tests\\test_classification.py -> build\\lib.win32-3.8\\sklearn\\metrics\\tests\n    copying sklearn\\metrics\\tests\\test_common.py -> build\\lib.win32-3.8\\sklearn\\metrics\\tests\n    copying sklearn\\metrics\\tests\\test_pairwise.py -> build\\lib.win32-3.8\\sklearn\\metrics\\tests\n    copying sklearn\\metrics\\tests\\test_ranking.py -> build\\lib.win32-3.8\\sklearn\\metrics\\tests\n    copying sklearn\\metrics\\tests\\test_regression.py -> build\\lib.win32-3.8\\sklearn\\metrics\\tests\n    copying sklearn\\metrics\\tests\\test_score_objects.py -> build\\lib.win32-3.8\\sklearn\\metrics\\tests\n    copying sklearn\\metrics\\tests\\__init__.py -> build\\lib.win32-3.8\\sklearn\\metrics\\tests\n    creating build\\lib.win32-3.8\\sklearn\\neighbors\n    copying sklearn\\neighbors\\approximate.py -> build\\lib.win32-3.8\\sklearn\\neighbors\n    copying sklearn\\neighbors\\base.py -> build\\lib.win32-3.8\\sklearn\\neighbors\n    copying sklearn\\neighbors\\classification.py -> build\\lib.win32-3.8\\sklearn\\neighbors\n    copying sklearn\\neighbors\\graph.py -> build\\lib.win32-3.8\\sklearn\\neighbors\n    copying sklearn\\neighbors\\kde.py -> build\\lib.win32-3.8\\sklearn\\neighbors\n    copying sklearn\\neighbors\\lof.py -> build\\lib.win32-3.8\\sklearn\\neighbors\n    copying sklearn\\neighbors\\nearest_centroid.py -> build\\lib.win32-3.8\\sklearn\\neighbors\n    copying sklearn\\neighbors\\regression.py -> build\\lib.win32-3.8\\sklearn\\neighbors\n    copying sklearn\\neighbors\\setup.py -> build\\lib.win32-3.8\\sklearn\\neighbors\n    copying sklearn\\neighbors\\unsupervised.py -> build\\lib.win32-3.8\\sklearn\\neighbors\n    copying sklearn\\neighbors\\__init__.py -> build\\lib.win32-3.8\\sklearn\\neighbors\n    creating build\\lib.win32-3.8\\sklearn\\neighbors\\tests\n    copying sklearn\\neighbors\\tests\\test_approximate.py -> build\\lib.win32-3.8\\sklearn\\neighbors\\tests\n    copying sklearn\\neighbors\\tests\\test_ball_tree.py -> build\\lib.win32-3.8\\sklearn\\neighbors\\tests\n    copying sklearn\\neighbors\\tests\\test_dist_metrics.py -> build\\lib.win32-3.8\\sklearn\\neighbors\\tests\n    copying sklearn\\neighbors\\tests\\test_kde.py -> build\\lib.win32-3.8\\sklearn\\neighbors\\tests\n    copying sklearn\\neighbors\\tests\\test_kd_tree.py -> build\\lib.win32-3.8\\sklearn\\neighbors\\tests\n    copying sklearn\\neighbors\\tests\\test_lof.py -> build\\lib.win32-3.8\\sklearn\\neighbors\\tests\n    copying sklearn\\neighbors\\tests\\test_nearest_centroid.py -> build\\lib.win32-3.8\\sklearn\\neighbors\\tests\n    copying sklearn\\neighbors\\tests\\test_neighbors.py -> build\\lib.win32-3.8\\sklearn\\neighbors\\tests\n    copying sklearn\\neighbors\\tests\\test_quad_tree.py -> build\\lib.win32-3.8\\sklearn\\neighbors\\tests\n    copying sklearn\\neighbors\\tests\\__init__.py -> build\\lib.win32-3.8\\sklearn\\neighbors\\tests\n    creating build\\lib.win32-3.8\\sklearn\\tree\n    copying sklearn\\tree\\export.py -> build\\lib.win32-3.8\\sklearn\\tree\n    copying sklearn\\tree\\setup.py -> build\\lib.win32-3.8\\sklearn\\tree\n    copying sklearn\\tree\\tree.py -> build\\lib.win32-3.8\\sklearn\\tree\n    copying sklearn\\tree\\__init__.py -> build\\lib.win32-3.8\\sklearn\\tree\n    creating build\\lib.win32-3.8\\sklearn\\tree\\tests\n    copying sklearn\\tree\\tests\\test_export.py -> build\\lib.win32-3.8\\sklearn\\tree\\tests\n    copying sklearn\\tree\\tests\\test_tree.py -> build\\lib.win32-3.8\\sklearn\\tree\\tests\n    copying sklearn\\tree\\tests\\__init__.py -> build\\lib.win32-3.8\\sklearn\\tree\\tests\n    creating build\\lib.win32-3.8\\sklearn\\svm\n    copying sklearn\\svm\\base.py -> build\\lib.win32-3.8\\sklearn\\svm\n    copying sklearn\\svm\\bounds.py -> build\\lib.win32-3.8\\sklearn\\svm\n    copying sklearn\\svm\\classes.py -> build\\lib.win32-3.8\\sklearn\\svm\n    copying sklearn\\svm\\setup.py -> build\\lib.win32-3.8\\sklearn\\svm\n    copying sklearn\\svm\\__init__.py -> build\\lib.win32-3.8\\sklearn\\svm\n    creating build\\lib.win32-3.8\\sklearn\\svm\\tests\n    copying sklearn\\svm\\tests\\test_bounds.py -> build\\lib.win32-3.8\\sklearn\\svm\\tests\n    copying sklearn\\svm\\tests\\test_sparse.py -> build\\lib.win32-3.8\\sklearn\\svm\\tests\n    copying sklearn\\svm\\tests\\test_svm.py -> build\\lib.win32-3.8\\sklearn\\svm\\tests\n    copying sklearn\\svm\\tests\\__init__.py -> build\\lib.win32-3.8\\sklearn\\svm\\tests\n    creating build\\lib.win32-3.8\\sklearn\\linear_model\n    copying sklearn\\linear_model\\base.py -> build\\lib.win32-3.8\\sklearn\\linear_model\n    copying sklearn\\linear_model\\bayes.py -> build\\lib.win32-3.8\\sklearn\\linear_model\n    copying sklearn\\linear_model\\coordinate_descent.py -> build\\lib.win32-3.8\\sklearn\\linear_model\n    copying sklearn\\linear_model\\huber.py -> build\\lib.win32-3.8\\sklearn\\linear_model\n    copying sklearn\\linear_model\\least_angle.py -> build\\lib.win32-3.8\\sklearn\\linear_model\n    copying sklearn\\linear_model\\logistic.py -> build\\lib.win32-3.8\\sklearn\\linear_model\n    copying sklearn\\linear_model\\omp.py -> build\\lib.win32-3.8\\sklearn\\linear_model\n    copying sklearn\\linear_model\\passive_aggressive.py -> build\\lib.win32-3.8\\sklearn\\linear_model\n    copying sklearn\\linear_model\\perceptron.py -> build\\lib.win32-3.8\\sklearn\\linear_model\n    copying sklearn\\linear_model\\randomized_l1.py -> build\\lib.win32-3.8\\sklearn\\linear_model\n    copying sklearn\\linear_model\\ransac.py -> build\\lib.win32-3.8\\sklearn\\linear_model\n    copying sklearn\\linear_model\\ridge.py -> build\\lib.win32-3.8\\sklearn\\linear_model\n    copying sklearn\\linear_model\\sag.py -> build\\lib.win32-3.8\\sklearn\\linear_model\n    copying sklearn\\linear_model\\setup.py -> build\\lib.win32-3.8\\sklearn\\linear_model\n    copying sklearn\\linear_model\\stochastic_gradient.py -> build\\lib.win32-3.8\\sklearn\\linear_model\n    copying sklearn\\linear_model\\theil_sen.py -> build\\lib.win32-3.8\\sklearn\\linear_model\n    copying sklearn\\linear_model\\__init__.py -> build\\lib.win32-3.8\\sklearn\\linear_model\n    creating build\\lib.win32-3.8\\sklearn\\linear_model\\tests\n    copying sklearn\\linear_model\\tests\\test_base.py -> build\\lib.win32-3.8\\sklearn\\linear_model\\tests\n    copying sklearn\\linear_model\\tests\\test_bayes.py -> build\\lib.win32-3.8\\sklearn\\linear_model\\tests\n    copying sklearn\\linear_model\\tests\\test_coordinate_descent.py -> build\\lib.win32-3.8\\sklearn\\linear_model\\tests\n    copying sklearn\\linear_model\\tests\\test_huber.py -> build\\lib.win32-3.8\\sklearn\\linear_model\\tests\n    copying sklearn\\linear_model\\tests\\test_least_angle.py -> build\\lib.win32-3.8\\sklearn\\linear_model\\tests\n    copying sklearn\\linear_model\\tests\\test_logistic.py -> build\\lib.win32-3.8\\sklearn\\linear_model\\tests\n    copying sklearn\\linear_model\\tests\\test_omp.py -> build\\lib.win32-3.8\\sklearn\\linear_model\\tests\n    copying sklearn\\linear_model\\tests\\test_passive_aggressive.py -> build\\lib.win32-3.8\\sklearn\\linear_model\\tests\n    copying sklearn\\linear_model\\tests\\test_perceptron.py -> build\\lib.win32-3.8\\sklearn\\linear_model\\tests\n    copying sklearn\\linear_model\\tests\\test_randomized_l1.py -> build\\lib.win32-3.8\\sklearn\\linear_model\\tests\n    copying sklearn\\linear_model\\tests\\test_ransac.py -> build\\lib.win32-3.8\\sklearn\\linear_model\\tests\n    copying sklearn\\linear_model\\tests\\test_ridge.py -> build\\lib.win32-3.8\\sklearn\\linear_model\\tests\n    copying sklearn\\linear_model\\tests\\test_sag.py -> build\\lib.win32-3.8\\sklearn\\linear_model\\tests\n    copying sklearn\\linear_model\\tests\\test_sgd.py -> build\\lib.win32-3.8\\sklearn\\linear_model\\tests\n    copying sklearn\\linear_model\\tests\\test_sparse_coordinate_descent.py -> build\\lib.win32-3.8\\sklearn\\linear_model\\tests\n    copying sklearn\\linear_model\\tests\\test_theil_sen.py -> build\\lib.win32-3.8\\sklearn\\linear_model\\tests\n    copying sklearn\\linear_model\\tests\\__init__.py -> build\\lib.win32-3.8\\sklearn\\linear_model\\tests\n    creating build\\lib.win32-3.8\\sklearn\\utils\n    copying sklearn\\utils\\arpack.py -> build\\lib.win32-3.8\\sklearn\\utils\n    copying sklearn\\utils\\bench.py -> build\\lib.win32-3.8\\sklearn\\utils\n    copying sklearn\\utils\\class_weight.py -> build\\lib.win32-3.8\\sklearn\\utils\n    copying sklearn\\utils\\deprecation.py -> build\\lib.win32-3.8\\sklearn\\utils\n    copying sklearn\\utils\\estimator_checks.py -> build\\lib.win32-3.8\\sklearn\\utils\n    copying sklearn\\utils\\extmath.py -> build\\lib.win32-3.8\\sklearn\\utils\n    copying sklearn\\utils\\fixes.py -> build\\lib.win32-3.8\\sklearn\\utils\n    copying sklearn\\utils\\graph.py -> build\\lib.win32-3.8\\sklearn\\utils\n    copying sklearn\\utils\\linear_assignment_.py -> build\\lib.win32-3.8\\sklearn\\utils\n    copying sklearn\\utils\\metaestimators.py -> build\\lib.win32-3.8\\sklearn\\utils\n    copying sklearn\\utils\\mocking.py -> build\\lib.win32-3.8\\sklearn\\utils\n    copying sklearn\\utils\\multiclass.py -> build\\lib.win32-3.8\\sklearn\\utils\n    copying sklearn\\utils\\optimize.py -> build\\lib.win32-3.8\\sklearn\\utils\n    copying sklearn\\utils\\random.py -> build\\lib.win32-3.8\\sklearn\\utils\n    copying sklearn\\utils\\setup.py -> build\\lib.win32-3.8\\sklearn\\utils\n    copying sklearn\\utils\\sparsefuncs.py -> build\\lib.win32-3.8\\sklearn\\utils\n    copying sklearn\\utils\\stats.py -> build\\lib.win32-3.8\\sklearn\\utils\n    copying sklearn\\utils\\testing.py -> build\\lib.win32-3.8\\sklearn\\utils\n    copying sklearn\\utils\\validation.py -> build\\lib.win32-3.8\\sklearn\\utils\n    copying sklearn\\utils\\_joblib.py -> build\\lib.win32-3.8\\sklearn\\utils\n    copying sklearn\\utils\\_scipy_sparse_lsqr_backport.py -> build\\lib.win32-3.8\\sklearn\\utils\n    copying sklearn\\utils\\_show_versions.py -> build\\lib.win32-3.8\\sklearn\\utils\n    copying sklearn\\utils\\_unittest_backport.py -> build\\lib.win32-3.8\\sklearn\\utils\n    copying sklearn\\utils\\__init__.py -> build\\lib.win32-3.8\\sklearn\\utils\n    creating build\\lib.win32-3.8\\sklearn\\utils\\sparsetools\n    copying sklearn\\utils\\sparsetools\\setup.py -> build\\lib.win32-3.8\\sklearn\\utils\\sparsetools\n    copying sklearn\\utils\\sparsetools\\__init__.py -> build\\lib.win32-3.8\\sklearn\\utils\\sparsetools\n    creating build\\lib.win32-3.8\\sklearn\\utils\\sparsetools\\tests\n    copying sklearn\\utils\\sparsetools\\tests\\__init__.py -> build\\lib.win32-3.8\\sklearn\\utils\\sparsetools\\tests\n    creating build\\lib.win32-3.8\\sklearn\\utils\\tests\n    copying sklearn\\utils\\tests\\test_bench.py -> build\\lib.win32-3.8\\sklearn\\utils\\tests\n    copying sklearn\\utils\\tests\\test_class_weight.py -> build\\lib.win32-3.8\\sklearn\\utils\\tests\n    copying sklearn\\utils\\tests\\test_deprecation.py -> build\\lib.win32-3.8\\sklearn\\utils\\tests\n    copying sklearn\\utils\\tests\\test_estimator_checks.py -> build\\lib.win32-3.8\\sklearn\\utils\\tests\n    copying sklearn\\utils\\tests\\test_extmath.py -> build\\lib.win32-3.8\\sklearn\\utils\\tests\n    copying sklearn\\utils\\tests\\test_fast_dict.py -> build\\lib.win32-3.8\\sklearn\\utils\\tests\n    copying sklearn\\utils\\tests\\test_fixes.py -> build\\lib.win32-3.8\\sklearn\\utils\\tests\n    copying sklearn\\utils\\tests\\test_graph.py -> build\\lib.win32-3.8\\sklearn\\utils\\tests\n    copying sklearn\\utils\\tests\\test_linear_assignment.py -> build\\lib.win32-3.8\\sklearn\\utils\\tests\n    copying sklearn\\utils\\tests\\test_metaestimators.py -> build\\lib.win32-3.8\\sklearn\\utils\\tests\n    copying sklearn\\utils\\tests\\test_multiclass.py -> build\\lib.win32-3.8\\sklearn\\utils\\tests\n    copying sklearn\\utils\\tests\\test_murmurhash.py -> build\\lib.win32-3.8\\sklearn\\utils\\tests\n    copying sklearn\\utils\\tests\\test_optimize.py -> build\\lib.win32-3.8\\sklearn\\utils\\tests\n    copying sklearn\\utils\\tests\\test_random.py -> build\\lib.win32-3.8\\sklearn\\utils\\tests\n    copying sklearn\\utils\\tests\\test_seq_dataset.py -> build\\lib.win32-3.8\\sklearn\\utils\\tests\n    copying sklearn\\utils\\tests\\test_shortest_path.py -> build\\lib.win32-3.8\\sklearn\\utils\\tests\n    copying sklearn\\utils\\tests\\test_show_versions.py -> build\\lib.win32-3.8\\sklearn\\utils\\tests\n    copying sklearn\\utils\\tests\\test_sparsefuncs.py -> build\\lib.win32-3.8\\sklearn\\utils\\tests\n    copying sklearn\\utils\\tests\\test_stats.py -> build\\lib.win32-3.8\\sklearn\\utils\\tests\n    copying sklearn\\utils\\tests\\test_testing.py -> build\\lib.win32-3.8\\sklearn\\utils\\tests\n    copying sklearn\\utils\\tests\\test_utils.py -> build\\lib.win32-3.8\\sklearn\\utils\\tests\n    copying sklearn\\utils\\tests\\test_validation.py -> build\\lib.win32-3.8\\sklearn\\utils\\tests\n    copying sklearn\\utils\\tests\\__init__.py -> build\\lib.win32-3.8\\sklearn\\utils\\tests\n    creating build\\lib.win32-3.8\\sklearn\\tests\n    copying sklearn\\tests\\test_base.py -> build\\lib.win32-3.8\\sklearn\\tests\n    copying sklearn\\tests\\test_calibration.py -> build\\lib.win32-3.8\\sklearn\\tests\n    copying sklearn\\tests\\test_check_build.py -> build\\lib.win32-3.8\\sklearn\\tests\n    copying sklearn\\tests\\test_common.py -> build\\lib.win32-3.8\\sklearn\\tests\n    copying sklearn\\tests\\test_config.py -> build\\lib.win32-3.8\\sklearn\\tests\n    copying sklearn\\tests\\test_discriminant_analysis.py -> build\\lib.win32-3.8\\sklearn\\tests\n    copying sklearn\\tests\\test_docstring_parameters.py -> build\\lib.win32-3.8\\sklearn\\tests\n    copying sklearn\\tests\\test_dummy.py -> build\\lib.win32-3.8\\sklearn\\tests\n    copying sklearn\\tests\\test_impute.py -> build\\lib.win32-3.8\\sklearn\\tests\n    copying sklearn\\tests\\test_init.py -> build\\lib.win32-3.8\\sklearn\\tests\n    copying sklearn\\tests\\test_isotonic.py -> build\\lib.win32-3.8\\sklearn\\tests\n    copying sklearn\\tests\\test_kernel_approximation.py -> build\\lib.win32-3.8\\sklearn\\tests\n    copying sklearn\\tests\\test_kernel_ridge.py -> build\\lib.win32-3.8\\sklearn\\tests\n    copying sklearn\\tests\\test_metaestimators.py -> build\\lib.win32-3.8\\sklearn\\tests\n    copying sklearn\\tests\\test_multiclass.py -> build\\lib.win32-3.8\\sklearn\\tests\n    copying sklearn\\tests\\test_multioutput.py -> build\\lib.win32-3.8\\sklearn\\tests\n    copying sklearn\\tests\\test_naive_bayes.py -> build\\lib.win32-3.8\\sklearn\\tests\n    copying sklearn\\tests\\test_pipeline.py -> build\\lib.win32-3.8\\sklearn\\tests\n    copying sklearn\\tests\\test_random_projection.py -> build\\lib.win32-3.8\\sklearn\\tests\n    copying sklearn\\tests\\test_site_joblib.py -> build\\lib.win32-3.8\\sklearn\\tests\n    copying sklearn\\tests\\__init__.py -> build\\lib.win32-3.8\\sklearn\\tests\n    running build_clib\n    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n    customize MSVCCompiler\n    Missing compiler_cxx fix for MSVCCompiler\n    customize MSVCCompiler using build_clib\n    building 'libsvm-skl' library\n    compiling C sources\n    error: Microsoft Visual C++ 14.0 is required. Get it with \"Build Tools for Visual Studio\": https://visualstudio.microsoft.com/downloads/\n    ----------------------------------------\nERROR: Command errored out with exit status 1: 'c:\\users\\gds_f\\appdata\\local\\programs\\python\\python38-32\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\gds_f\\\\AppData\\\\Local\\\\Temp\\\\pip-install-e6t25tz6\\\\scikit-learn\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\gds_f\\\\AppData\\\\Local\\\\Temp\\\\pip-install-e6t25tz6\\\\scikit-learn\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\gds_f\\AppData\\Local\\Temp\\pip-record-xr0ajv7e\\install-record.txt' --single-version-externally-managed --compile --install-headers 'c:\\users\\gds_f\\appdata\\local\\programs\\python\\python38-32\\Include\\scikit-learn' Check the logs for full command output.\nWARNING: You are using pip version 20.0.2; however, version 20.2.2 is available.\nYou should consider upgrading via the 'c:\\users\\gds_f\\appdata\\local\\programs\\python\\python38-32\\python.exe -m pip install --upgrade pip' command.\nCollecting xgboost==0.71WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\nPlease see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\nTo avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\nERROR: Files/directories not found in C:\\Users\\gds_f\\AppData\\Local\\Temp\\pip-install-d6tr9ssy\\xgboost\\pip-egg-info\nWARNING: You are using pip version 20.0.2; however, version 20.2.2 is available.\nYou should consider upgrading via the 'c:\\users\\gds_f\\appdata\\local\\programs\\python\\python38-32\\python.exe -m pip install --upgrade pip' command.\n\n  Using cached xgboost-0.71.tar.gz (494 kB)\n"
    }
   ],
   "source": [
    "# Primeiro, realizamos a instalação do scikit-learn versão 0.20.3 e do xgboost versão 0.71 no Kernel deste notebook\n",
    "# ** CUIDADO AO TROCAR A VERSÃO DAS BIBLIOTECAS -- VERSÕES DIFERENTES PODEM SER INCOMPATÍVEIS COM O WATSON STUDIO **\n",
    "# OBS: A instalação do xgboost leva um tempo considerável\n",
    "!pip install scikit-learn==0.20.3 --upgrade\n",
    "!pip install xgboost==0.71 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-d62fb2fc21a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Pacote para exploração e análise de dados\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Pacote com métodos numéricos e representações matriciais\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Em seguida iremos importar diversas bibliotecas que serão utilizadas:\n",
    "\n",
    "# Pacote para trabalhar com JSON\n",
    "import json\n",
    "\n",
    "# Pacote para realizar requisições HTTP\n",
    "import requests\n",
    "\n",
    "# Pacote para exploração e análise de dados\n",
    "import pandas as pd\n",
    "\n",
    "# Pacote com métodos numéricos e representações matriciais\n",
    "import numpy as np\n",
    "\n",
    "# Pacote para construção de modelo baseado na técnica Gradient Boosting\n",
    "import xgboost as xgb\n",
    "\n",
    "# Pacotes do scikit-learn para pré-processamento de dados\n",
    "# \"SimpleImputer\" é uma transformação para preencher valores faltantes em conjuntos de dados\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Pacotes do scikit-learn para treinamento de modelos e construção de pipelines\n",
    "# Método para separação de conjunto de dados em amostras de treino e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Método para criação de modelos baseados em árvores de decisão\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Classe para a criação de uma pipeline de machine-learning\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Pacotes do scikit-learn para avaliação de modelos\n",
    "# Métodos para validação cruzada do modelo criado\n",
    "from sklearn.model_selection import KFold, cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando um .csv de seu projeto no IBM Cloud Pak for Data para o Kernel deste notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro iremos importar o dataset fornecido para o desafio, que já está incluso neste projeto!\n",
    "\n",
    "Você pode realizar a importação dos dados de um arquivo .csv diretamente para o Kernel do notebook como um DataFrame da biblioteca Pandas, muito utilizada para a manipulação de dados em Python.\n",
    "\n",
    "Para realizar a importação, basta selecionar a próxima célula e seguir as instruções na imagem abaixo:\n",
    "\n",
    "![alt text](https://i.imgur.com/K1DwL9I.png \"importing-csv-as-df\")\n",
    "\n",
    "Após a seleção da opção **\"Insert to code\"**, a célula abaixo será preenchida com o código necessário para importação e leitura dos dados no arquivo .csv como um DataFrame Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'dataset_desafio_2' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-5f60bef72f68>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_data_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_desafio_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset_desafio_2' is not defined"
     ]
    }
   ],
   "source": [
    "df_data_1 = read_csv(dataset_desafio_2.csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos 15 colunas presentes no dataset fornecido, sendo dezessete delas variáveis características (dados de entrada) e um delas uma variável-alvo (que queremos que o nosso modelo seja capaz de prever). \n",
    "\n",
    "As variáveis características são:\n",
    "\n",
    "    MATRICULA       - número de matrícula do estudante\n",
    "    NOME            - nome completo do estudante\n",
    "    REPROVACOES_DE  - número de reprovações na disciplina de ``Direito Empresarial``\n",
    "    REPROVACOES_EM  - número de reprovações na disciplina de ``Empreendedorismo``\n",
    "    REPROVACOES_MF  - número de reprovações na disciplina de ``Matemática Financeira``\n",
    "    REPROVACOES_GO  - número de reprovações na disciplina de ``Gestão Operacional``\n",
    "    NOTA_DE         - média simples das notas do aluno na disciplina de ``Direito Empresarial`` (0-10)\n",
    "    NOTA_EM         - média simples das notas do aluno na disciplina de ``Empreendedorismo`` (0-10)\n",
    "    NOTA_MF         - média simples das notas do aluno na disciplina de ``Matemática Financeira`` (0-10)\n",
    "    NOTA_GO         - média simples das notas do aluno na disciplina de ``Gestão Operacional`` (0-10)\n",
    "    INGLES          - variável binária que indica se o estudante tem conhecimento em língua inglesa (0 -> sim ou 1 -> não).\n",
    "    H_AULA_PRES     - horas de estudo presencial realizadas pelo estudante\n",
    "    TAREFAS_ONLINE  - número de tarefas online entregues pelo estudante\n",
    "    FALTAS          - número de faltas acumuladas do estudante (todas disciplinas)\n",
    "    \n",
    "A variável-alvo é:\n",
    "\n",
    "    PERFIL               - uma *string* que indica uma de cinco possibilidades: \n",
    "        \"EXCELENTE\"      - Estudante não necessita de mentoria\n",
    "        \"MUITO BOM\"      - Estudante não necessita de mentoria\n",
    "        \"HUMANAS\"        - Estudante necessita de mentoria exclusivamente em matérias com conteúdo de ciências humanas\n",
    "        \"EXATAS\"         - Estudante necessita de mentoria apenas em disciplinas com conteúdo de ciências exatas\n",
    "        \"DIFICULDADE\"    - Estudante necessita de mentoria em duas ou mais disciplinas\n",
    "        \n",
    "Com um modelo capaz de classificar um estudante em uma dessas categorias, podemos automatizar parte da mentoria estudantil através de assistentes virtuais, que serão capazes de recomendar práticas de estudo e conteúdo personalizado com base nas necessidades de cada aluno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explorando os dados fornecidos\n",
    "\n",
    "Podemos continuar a exploração dos dados fornecidos com a função ``info()``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df_data_1' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-dba20155959b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_data_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_data_1' is not defined"
     ]
    }
   ],
   "source": [
    "df_data_1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É notado que existem variáveis do tipo ``float64`` (números \"decimais\"), variáveis do tipo ``int64`` (números inteiros) e do tipo ``object`` (nesse caso são *strings*, ou texto). \n",
    "\n",
    "Como a maioria dos algoritmos de aprendizado estatístico supervisionado só aceita valores numéricos como entrada, é necessário então o pré-processamento das variáveis do tipo \"object\" antes de usar esse dataset como entrada para o treinamento de um modelo. Também é notado que existem valores faltantes em várias colunas. Esses valores faltantes também devem ser tratados antes de serem construídos modelos com esse conjunto de dados base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função ``describe()`` gera várias informações sobre as variáveis numéricas que também podem ser úteis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df_data_1' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-14eecf06361f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_data_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_data_1' is not defined"
     ]
    }
   ],
   "source": [
    "df_data_1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizações\n",
    "\n",
    "Para visualizar o dataset fornecido, podemos utilizar as bibliotecas ``matplotlib`` e ``seaborn``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-d634cccf6488>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-2afd684a9ffd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcountplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'REPROVACOES_DE'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_data_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcountplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'REPROVACOES_EM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_data_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcountplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'REPROVACOES_MF'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_data_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(28, 4))\n",
    "\n",
    "sns.countplot(ax=axes[0], x='REPROVACOES_DE', data=df_data_1)\n",
    "sns.countplot(ax=axes[1], x='REPROVACOES_EM', data=df_data_1)\n",
    "sns.countplot(ax=axes[2], x='REPROVACOES_MF', data=df_data_1)\n",
    "sns.countplot(ax=axes[3], x='REPROVACOES_GO', data=df_data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-527b51d4ac30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_data_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'NOTA_DE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_data_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'NOTA_EM'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_data_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'NOTA_MF'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(28, 4))\n",
    "\n",
    "sns.distplot(df_data_1['NOTA_DE'], ax=axes[0])\n",
    "sns.distplot(df_data_1['NOTA_EM'], ax=axes[1])\n",
    "sns.distplot(df_data_1['NOTA_MF'], ax=axes[2])\n",
    "sns.distplot(df_data_1['NOTA_GO'].dropna(), ax=axes[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-6bfc82204bdf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcountplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'INGLES'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_data_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcountplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'FALTAS'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_data_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcountplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'H_AULA_PRES'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_data_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(28, 4))\n",
    "\n",
    "sns.countplot(ax=axes[0], x='INGLES', data=df_data_1)\n",
    "sns.countplot(ax=axes[1], x='FALTAS', data=df_data_1)\n",
    "sns.countplot(ax=axes[2], x='H_AULA_PRES', data=df_data_1)\n",
    "sns.countplot(ax=axes[3], x='TAREFAS_ONLINE', data=df_data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-bbbc078618a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcountplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'PERFIL'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_data_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig = plt.plot()\n",
    "sns.countplot(x='PERFIL', data=df_data_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ** ATENÇÃO **\n",
    "\n",
    "Você pode notar pela figura acima que este dataset é desbalanceado, isto é, a quantidade de amostras para cada classe que desejamos classificar é bem discrepante. O participante é livre para adicionar ou remover **LINHAS** no dataset fornecido, inclusive utilizar bibliotecas para balanceamento com ``imblearn``. Entretanto tome **muito cuidado**!!! Você não pode alterar os tipos dos dados e nem remover ou desordenar o dataset fornecido. Todas as operações desse tipo deverão ser feitas por meio de Transforms do scikit-learn :)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizando o pré-processamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o pré-processamento dos dados serão apresentadas duas transformações básicas neste notebook, demonstrando a construção de uma Pipeline com um modelo funcional. Esta Pipeline funcional fornecida deverá ser melhorada pelo participante para que o modelo final alcance a maior acurácia possível, garantindo uma pontuação maior no desafio. Essa melhoria pode ser feita apenas no pré-processamento dos dados, na escolha de um algoritmo para treinamento de modelo diferente, ou até mesmo na alteração do *framework* usado (entretanto só será fornecido um exemplo pronto de integração do Watson Machine Learning com o *scikit-learn*).\n",
    "\n",
    "A primeira transformação (passo na nossa Pipeline) será a exclusão da coluna \"NOME\" do nosso dataset, que além de não ser uma variável numérica, também não é uma variável relacionada ao desempenho dos estudantes nas disciplinas. Existem funções prontas no scikit-learn para a realização dessa transformação, entretanto nosso exemplo irá demonstrar como criar uma transformação personalizada do zero no scikit-learn. Se desejado, o participante poderá utilizar esse exemplo para criar outras transformações e adicioná-las à Pipeline final :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformação 1: excluindo colunas do dataset\n",
    "\n",
    "Para a criação de uma transformação de dados personalizada no scikit-learn, é necessária basicamente a criação de uma classe com os métodos ``transform`` e ``fit``. No método transform será executada a lógica da nossa transformação.\n",
    "\n",
    "Na próxima célula é apresentado o código completo de uma transformação ``DropColumns`` para a remoção de colunas de um DataFrame pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-e4415934cd20>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseEstimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTransformerMixin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# All sklearn Transforms must have the `transform` and `fit` methods\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDropColumns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseEstimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTransformerMixin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "# All sklearn Transforms must have the `transform` and `fit` methods\n",
    "class DropColumns(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Primeiro realizamos a cópia do dataframe 'X' de entrada\n",
    "        data = X.copy()\n",
    "        # Retornamos um novo dataframe sem as colunas indesejadas\n",
    "        return data.drop(labels=self.columns, axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para aplicar essa transformação em um DataFrame pandas, basta instanciar um objeto *DropColumns* e chamar o método transform()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'DropColumns' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-6578669eb754>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Instanciando uma transformação DropColumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m rm_columns = DropColumns(\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"NOME\"\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Essa transformação recebe como parâmetro uma lista com os nomes das colunas indesejadas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m )\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DropColumns' is not defined"
     ]
    }
   ],
   "source": [
    "# Instanciando uma transformação DropColumns\n",
    "rm_columns = DropColumns(\n",
    "    columns=[\"NOME\"]  # Essa transformação recebe como parâmetro uma lista com os nomes das colunas indesejadas\n",
    ")\n",
    "\n",
    "print(rm_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Colunas do dataset original: \n\n"
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df_data_1' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-35e4b964e950>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Visualizando as colunas do dataset original\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Colunas do dataset original: \\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_data_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_data_1' is not defined"
     ]
    }
   ],
   "source": [
    "# Visualizando as colunas do dataset original\n",
    "print(\"Colunas do dataset original: \\n\")\n",
    "print(df_data_1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'rm_columns' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-9c024adc492d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Aplicando a transformação ``DropColumns`` ao conjunto de dados base\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrm_columns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_data_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Reconstruindo um DataFrame Pandas com o resultado da transformação\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m df_data_2 = pd.DataFrame.from_records(\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rm_columns' is not defined"
     ]
    }
   ],
   "source": [
    "# Aplicando a transformação ``DropColumns`` ao conjunto de dados base\n",
    "rm_columns.fit(X=df_data_1)\n",
    "\n",
    "# Reconstruindo um DataFrame Pandas com o resultado da transformação\n",
    "df_data_2 = pd.DataFrame.from_records(\n",
    "    data=rm_columns.transform(\n",
    "        X=df_data_1\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Colunas do dataset após a transformação ``DropColumns``: \n\n"
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df_data_2' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-8967f42bdeae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Visualizando as colunas do dataset transformado\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Colunas do dataset após a transformação ``DropColumns``: \\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_data_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_data_2' is not defined"
     ]
    }
   ],
   "source": [
    "# Visualizando as colunas do dataset transformado\n",
    "print(\"Colunas do dataset após a transformação ``DropColumns``: \\n\")\n",
    "print(df_data_2.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota-se que a coluna \"NOME\" foi removida e nosso dataset agora poossui apenas 17 colunas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformação 2: tratando dados faltantes\n",
    "\n",
    "Para tratar os dados faltantes em nosso conjunto de dados, iremos agora utilizar uma transformação pronta da biblioteca scikit-learn, chamada **SimpleImputer**.\n",
    "\n",
    "Essa transformação permite diversas estratégias para o tratamento de dados faltantes. A documentação oficial pode ser encontrada em: https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html\n",
    "\n",
    "Neste exemplo iremos simplesmente transformar todos os valores faltantes em zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'SimpleImputer' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-ab5dcc5dcbfe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Criação de um objeto ``SimpleImputer``\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m si = SimpleImputer(\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mmissing_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# os valores faltantes são do tipo ``np.nan`` (padrão Pandas)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mstrategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'constant'\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# a estratégia escolhida é a alteração do valor faltante por uma constante\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# a constante que será usada para preenchimento dos valores faltantes é um int64=0.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SimpleImputer' is not defined"
     ]
    }
   ],
   "source": [
    "# Criação de um objeto ``SimpleImputer``\n",
    "si = SimpleImputer(\n",
    "    missing_values=np.nan,  # os valores faltantes são do tipo ``np.nan`` (padrão Pandas)\n",
    "    strategy='constant',  # a estratégia escolhida é a alteração do valor faltante por uma constante\n",
    "    fill_value=0,  # a constante que será usada para preenchimento dos valores faltantes é um int64=0.\n",
    "    verbose=0,\n",
    "    copy=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df_data_2' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-3122a98d9c13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Visualizando os dados faltantes do dataset após a primeira transformação (df_data_2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Valores nulos antes da transformação SimpleImputer: \\n\\n{}\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_data_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_data_2' is not defined"
     ]
    }
   ],
   "source": [
    "# Visualizando os dados faltantes do dataset após a primeira transformação (df_data_2)\n",
    "print(\"Valores nulos antes da transformação SimpleImputer: \\n\\n{}\\n\".format(df_data_2.isnull().sum(axis = 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'si' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-adb6c941d58d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Aplicamos o SimpleImputer ``si`` ao conjunto de dados df_data_2 (resultado da primeira transformação)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_data_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Reconstrução de um novo DataFrame Pandas com o conjunto imputado (df_data_3)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m df_data_3 = pd.DataFrame.from_records(\n",
      "\u001b[1;31mNameError\u001b[0m: name 'si' is not defined"
     ]
    }
   ],
   "source": [
    "# Aplicamos o SimpleImputer ``si`` ao conjunto de dados df_data_2 (resultado da primeira transformação)\n",
    "si.fit(X=df_data_2)\n",
    "\n",
    "# Reconstrução de um novo DataFrame Pandas com o conjunto imputado (df_data_3)\n",
    "df_data_3 = pd.DataFrame.from_records(\n",
    "    data=si.transform(\n",
    "        X=df_data_2\n",
    "    ),  # o resultado SimpleImputer.transform(<<pandas dataframe>>) é lista de listas\n",
    "    columns=df_data_2.columns  # as colunas originais devem ser conservadas nessa transformação\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df_data_3' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-64453de7d695>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Visualizando os dados faltantes do dataset após a segunda transformação (SimpleImputer) (df_data_3)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Valores nulos no dataset após a transformação SimpleImputer: \\n\\n{}\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_data_3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_data_3' is not defined"
     ]
    }
   ],
   "source": [
    "# Visualizando os dados faltantes do dataset após a segunda transformação (SimpleImputer) (df_data_3)\n",
    "print(\"Valores nulos no dataset após a transformação SimpleImputer: \\n\\n{}\\n\".format(df_data_3.isnull().sum(axis = 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota-se que não temos mais nenhum valor faltante no nosso conjunto de dados :)\n",
    "\n",
    "Vale salientar que nem sempre a alteração dos valores faltantes por 0 é a melhor estratégia. O participante é incentivado a estudar e implementar estratégias diferentes de tratamento dos valores faltantes para aprimorar seu modelo e melhorar sua pontuação final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando um modelo de classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalizado o pré-processamento, já temos o conjunto de dados no formato necessário para o treinamento do nosso modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df_data_3' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-68b2505091fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_data_3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_data_3' is not defined"
     ]
    }
   ],
   "source": [
    "df_data_3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No exemplo fornecido, iremos utilizar todas as colunas, exceto a coluna **LABELS** como *features* (variáveis de entrada).\n",
    "\n",
    "A variável **LABELS** será a variável-alvo do modelo, conforme descrito no enunciado do desafio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definindo as features do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df_data_3' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-11d736dad4a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Preparação dos argumentos para os métodos da biblioteca ``scikit-learn``\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_data_3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_data_3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_data_3' is not defined"
     ]
    }
   ],
   "source": [
    "# Definição das colunas que serão features (nota-se que a coluna NOME não está presente)\n",
    "features = [\n",
    "    \"MATRICULA\", 'REPROVACOES_DE', 'REPROVACOES_EM', \"REPROVACOES_MF\", \"REPROVACOES_GO\",\n",
    "    \"NOTA_DE\", \"NOTA_EM\", \"NOTA_MF\", \"NOTA_GO\",\n",
    "    \"INGLES\", \"H_AULA_PRES\", \"TAREFAS_ONLINE\", \"FALTAS\", \n",
    "]\n",
    "\n",
    "# Definição da variável-alvo\n",
    "target = [\"PERFIL\"]\n",
    "\n",
    "# Preparação dos argumentos para os métodos da biblioteca ``scikit-learn``\n",
    "X = df_data_3[features]\n",
    "y = df_data_3[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O conjunto de entrada (X):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-ae5cd47bda90>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As variáveis-alvo correspondentes (y):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-17b2b1f6e15b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separando o dataset em um conjunto de treino e um conjunto de teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iremos separar o dataset fornecido em dois grupos: um para treinar nosso modelo, e outro para testarmos o resultado através de um teste cego. A separação do dataset pode ser feita facilmente com o método *train_test_split()* do scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-403793c2e26b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Separação dos dados em um conjunto de treino e um conjunto de teste\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m337\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "# Separação dos dados em um conjunto de treino e um conjunto de teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criando um modelo baseado em árvores de decisão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No exemplo fornecido iremos criar um classificador baseado em **árvores de decisão**.\n",
    "\n",
    "Material teórico sobre árvores de decisão na documentação oficial do scikit-learn: https://scikit-learn.org/stable/modules/tree.html\n",
    "\n",
    "O primeiro passo é basicamente instanciar um objeto *DecisionTreeClassifier()* da biblioteca scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'DecisionTreeClassifier' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-b1ffffb16c15>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Criação de uma árvore de decisão com a biblioteca ``scikit-learn``:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdecision_tree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'DecisionTreeClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# Criação de uma árvore de decisão com a biblioteca ``scikit-learn``:\n",
    "decision_tree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testando o classificador baseado em árvore de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'decision_tree' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-0b488e31e058>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Treino do modelo (é chamado o método *fit()* com os conjuntos de treino)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m decision_tree.fit(\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0my_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'decision_tree' is not defined"
     ]
    }
   ],
   "source": [
    "# Treino do modelo (é chamado o método *fit()* com os conjuntos de treino)\n",
    "decision_tree.fit(\n",
    "    X_train,\n",
    "    y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execução de predições e avaliação da árvore de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'decision_tree' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-9e38d1c7cc5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Realização de teste cego no modelo criado\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecision_tree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'decision_tree' is not defined"
     ]
    }
   ],
   "source": [
    "# Realização de teste cego no modelo criado\n",
    "y_pred = decision_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-c8ff277ea5c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-421157ec4fd7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-851b409050da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Acurácia alcançada pela árvore de decisão\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Acurácia: {}%\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Acurácia alcançada pela árvore de decisão\n",
    "print(\"Acurácia: {}%\".format(100*round(accuracy_score(y_test, y_pred), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste notebook foi demonstrado como trabalhar com transformações e modelos com a biblioteca scikit-learn. É recomendado que o participante realize seus experimentos editando o código fornecido aqui até que um modelo com acurácia elevada seja alcançado.\n",
    "\n",
    "Quando você estiver satisfeito com seu modelo, pode passar para a segunda etapa do desafio -- encapsular seu modelo como uma API REST pronta para uso com o Watson Machine Learning!\n",
    "\n",
    "O notebook para a segunda etapa já se encontra neste projeto, basta acessar a aba **ASSETS** e inicializá-lo! Não se esqueca de antes desligar o Kernel deste notebook para reduzir o consumo de sua camada grátis do IBM Cloud Pak for Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 32-bit",
   "language": "python",
   "name": "python_defaultSpec_1598490722327"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}